{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Propagation using Random Gaussian Numbers\n",
    "\n",
    "Example calculation of propagating uncertainties, both when adding and multiplying number, and also in the general case. The propagation can be done both analytically (using the error propagation formula) and also using simulation.\n",
    "\n",
    "The example is based on FIRST doing the error propagation analytically, and then verifying it by running a so-called Monte-Carlo (MC) program, which uses random numbers for propagating errors.\n",
    "\n",
    "## References:\n",
    "- Barlow: page 48-61\n",
    "- Bevington: page 36-48\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   12th of November 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "DO THE FOLLOWING ANALYTICAL EXERCISE FIRST!!!\n",
    "\n",
    "1. A class of students estimate by eye, that the length of the table in Auditorium A is $L = (3.5\\pm 0.4)$m, and that the width is $W = (0.8\\pm 0.2)$m.\n",
    "\n",
    "   Assuming that there is no correlation between these two measurements, calculate ANALYTICALLY what the Perimeter (P), area (A), and diagonal (D) length is including (propagated) uncertainties. Repeat the calculation, given that the correlation between length and width is $\\rho(L,W) = 0.5$ - not an unreasonable number, given that they are estimated by the same (uncertain) scale.\n",
    "   \n",
    "NOTE: This is a complete standard problem, that you will be asked to solve again and again in the course. For this reason, make sure that you understand how to do it, and become good at doing it reasonably fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters:\n",
    "mu1   =  3.5\n",
    "sig1  =  0.4\n",
    "mu2   =  0.8\n",
    "sig2  =  0.2\n",
    "rho12 =  0.5           # Correlation parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (-1.0 <= rho12 <= 1.0): \n",
    "    raise ValueError(f\"Correlation factor not in interval [-1,1], as it is {rho12:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on analytic solutions:\n",
    "\n",
    "Python includes symbolic algebra in the package *SymPy*, which seems to be both simple and powerful (and in Python). In addition, printing with Latex can also be included (see below), which (in combination) is very nice.\n",
    "\n",
    "Below is a SymPy and Latex example with the hope that it will wet your appetite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Latex\n",
    "\n",
    "def lprint(*args,**kwargs):\n",
    "    \"\"\"Pretty print arguments as LaTeX using IPython display system \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple \n",
    "        What to print (in LaTeX math mode)\n",
    "    kwargs : dict \n",
    "        optional keywords to pass to `display` \n",
    "    \"\"\"\n",
    "    display(Latex('$$'+' '.join(args)+'$$'),**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$P = 2 L + 2 W$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\sigma_{P} = \\sqrt{4 \\sigma_{L}^{2} + 4 \\sigma_{W}^{2}}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$P = (8.6 \\pm 0.9)\\,\\mathrm{m}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import SymPy: \n",
    "from sympy import * \n",
    "    \n",
    "# Define variables:\n",
    "L,W,P,A,D = symbols(\"L, W, P, A, D\")\n",
    "dL,dW,dP,dA,dD = symbols(\"sigma_L, sigma_W, sigma_P, sigma_A, sigma_D\")\n",
    "\n",
    "# Perimeter:\n",
    "# Define relation, and print:\n",
    "P = 2*L + 2*W\n",
    "lprint(latex(Eq(symbols('P'),P)))\n",
    "\n",
    "# Calculate uncertainty and print:\n",
    "dP = sqrt((P.diff(L) * dL)**2 + (P.diff(W) * dW)**2)\n",
    "lprint(latex(Eq(symbols('sigma_P'), dP)))\n",
    "\n",
    "# Turn expression into numerical functions \n",
    "fP = lambdify((L,W),P)\n",
    "fdP = lambdify((L,dL,W,dW),dP)\n",
    "\n",
    "# Define values and their errors\n",
    "vL, vdL = mu1,sig1\n",
    "vW, vdW = mu2,sig2\n",
    "\n",
    "# Numerically evaluate expressions and print \n",
    "vP = fP(vL,vW)\n",
    "vdP = fdP(vL,vdL,vW,vdW)\n",
    "lprint(fr'P = ({vP:.1f} \\pm {vdP:.1f})\\,\\mathrm{{m}}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NOTE: Do the above analytical calculation before you continue below! Possibly use SymPy for the differentiations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "import seaborn as sns                                  # Make the plots nicer to look at\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "import sys                                             # Modules to see files and folders in directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../External_Functions')\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax # useful functions to print fit results on figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error propagation - Simulation\n",
    "\n",
    "Now we want to try to see, if we can solve the above error propagation problem using simulation. The method is relatively straight forward: You simply take \"realistic\" values of the input parameters x (here Length (x1) and Width (x2)), calculate the resulting value y (here Perimeter, Area, and Diagonal), and do this many times. The resulting distribution of y should be centered around the value y(x1,x2), and the standard deviation should reflect the uncertainty in y from the uncertainties in the input variables.\n",
    "\n",
    "This is a much more clumsy of calculating the uncertainty, but comes with the advantage, that if the resulting uncertainty is not Gaussian, then one can actually see this (i.e. it avoids the assumptions used in the usual error propagation formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set the parameters of the program:\n",
    "N_exp = 10000           # Number of \"experiments\" (i.e. drawing from random distributions)\n",
    "save_plots = False\n",
    "r = np.random\n",
    "r.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for two random numbers (Gaussianly distributed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1   =  3.5\n",
    "sig1  =  0.4\n",
    "mu2   =  0.8\n",
    "sig2  =  0.2\n",
    "rho12 =  0.5           # Correlation parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (-1.0 <= rho12 <= 1.0): \n",
    "    raise ValueError(f\"Correlation factor not in interval [-1,1], as it is {rho12:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate numbers that allows the transform from uncorrelated variables `u` and `v` to correlated random numbers `x1` and `x2` below (see Barlow page 42-44 for method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters needed for the transformation:\n",
    "theta = 0.5 * np.arctan( 2.0 * rho12 * sig1 * sig2 / ( np.square(sig1) - np.square(sig2) ) )\n",
    "sigu = np.sqrt( np.abs( (((sig1*np.cos(theta))**2) - (sig2*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "sigv = np.sqrt( np.abs( (((sig2*np.cos(theta))**2) - (sig1*np.sin(theta))**2 ) / ( (np.cos(theta))**2 - np.sin(theta)**2) ) )\n",
    "\n",
    "# Produce random numbers with the (possible) correlation:\n",
    "u = r.normal(0.0, sigu, N_exp)\n",
    "v = r.normal(0.0, sigv, N_exp)\n",
    "x1_all = mu1 + np.cos(theta)*u - np.sin(theta)*v\n",
    "x2_all = mu2 + np.sin(theta)*u + np.cos(theta)*v\n",
    "x12_all = np.array([x1_all, x2_all])\n",
    "\n",
    "y_all = x1_all - 2*x2_all         # Silly formula - you have to put this in yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above is nothing more than a matrix multiplication written out! Also note that the absolute value is taken before the square root to avoid `np.sqrt(x)` with `x<0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Plot both input distribution and resulting 2D-histogram on screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "counts, xedges, yedges, im = ax.hist2d(x1_all, x2_all, bins=[120, 80], range= [[0.0, 6.0], [-1.0, 3.0]], cmin=1)\n",
    "ax.plot([0.0, 6.0], [0.0, 0.0], \"--k\")   # NOTE: This draws a line from [x1, x2], [y1, y2] with dashed line (\"--\") and in black (\"k\")\n",
    "fig.colorbar(im) # ticks=[-1, 0, 1]\n",
    "\n",
    "ax.set(title='Histogram of lengths (x) and widths (y)',\n",
    "       xlabel='x', \n",
    "       ylabel='y',\n",
    "       aspect='equal', # NOTE: This forces the x- and y-axis to have the SAME scale!!!\n",
    "      )\n",
    "\n",
    "d = {'Entries': len(x12_all),\n",
    "     'Mean x': x1_all.mean(),\n",
    "     'Mean y': x2_all.mean(),\n",
    "     'Std x': x1_all.std(ddof=1),\n",
    "     'Std y': x2_all.std(ddof=1),\n",
    "    }\n",
    "\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.02, 0.97, text, ax, fontsize=15);\n",
    "\n",
    "fig.tight_layout()\n",
    "fig\n",
    "\n",
    "if save_plots :\n",
    "    fig.savefig(\"Dist_2Dgauss.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we bin `y_all` and fit it with a Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, N, mu, sigma):\n",
    "    return N * 1.0 / (sigma*np.sqrt(2*np.pi)) * np.exp(-0.5* (x-mu)**2/sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = 0.0, 4.0\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 6));\n",
    "counts, bin_edges, _ = ax2.hist(y_all, 100, range=(xmin, xmax), histtype='step');\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "s_counts = np.sqrt(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the distribution of \"whatever you put into it\" (initially x1-2*x2), which shows what output you get and what uncertainty to expect (given by the width - think about this!). We can thus get the result by simply recording the mean and width (SD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  Mean = {y_all.mean():5.3f},    SD = {y_all.std(ddof=1):5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are in principle not even sure, if this distribution is Gaussian, so in order to check this, we fit it. Note that in the second line (defining the Minuit object to minimised) we give \"reasonable\" starting values, which is key to making fitting work (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chi2_object = Chi2Regression(gaussian, bin_centers[counts>0], counts[counts>0], s_counts[counts>0])\n",
    "minuit = Minuit(Chi2_object, pedantic=False, N=5000, mu=2.0, sigma=1.0, limit_sigma=(0, 10000), print_level=0) #   \n",
    "minuit.migrad()                          # Perform the actual fit\n",
    "\n",
    "for name in minuit.parameters:\n",
    "    print(\"Fit value: {0} = {1:.5f} +/- {2:.5f}\".format(name, minuit.values[name], minuit.errors[name]))\n",
    "\n",
    "chi2 = minuit.fval\n",
    "N_var = 3                                # Number of variables (N, mu, sigma)\n",
    "N_dof = len(counts[counts>0]) - N_var    # Number of degrees of freedom\n",
    "\n",
    "from scipy import stats\n",
    "chi2_prob =  stats.chi2.sf(chi2, N_dof) # The chi2 probability given N_DOF degrees of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the fit on top of the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis = gaussian(xaxis, *minuit.args)\n",
    "ax2.plot(xaxis, yaxis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Entries': len(y_all),\n",
    "     'Mean': y_all.mean(),\n",
    "     'Std': y_all.std(ddof=1),\n",
    "     'Chi2': chi2,\n",
    "     'NDF': N_dof,\n",
    "     'Prob': chi2_prob, \n",
    "     'N': [minuit.values['N'], minuit.errors['N']], \n",
    "     'mu': [minuit.values['mu'], minuit.errors['mu']], \n",
    "     'sigma': [minuit.values['sigma'], minuit.errors['sigma']],\n",
    "    }\n",
    "\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.02, 0.97, text, ax2, fontsize=14);\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if save_plots:\n",
    "    fig2.savefig(\"Dist_ErrorProp.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------- \n",
    "\n",
    "# Questions:\n",
    "\n",
    "0. First solve the problem of obtaining the Perimeter, Area & Diagonal with uncertainty ANALYTICALLY.\n",
    "\n",
    "1. Now look at the program, and assure yourself that you understand what is going on. Put in the correct expression for y in terms of x1=L and x2=W in order to calculate the circumference, area, and diagonal length, and run the program. Does the output correspond well with the results you expected from your analytical calculations to begin with?\n",
    "\n",
    "2. Imagine that you wanted to know the central value and uncertainty of y1 and y2, given the\n",
    "   same above PDFs for `x1`=$L$ and `x2`=$W$:\n",
    "   \n",
    "     `y1 = log(square(x1*tan(x2))+sqrt((x1-x2)/(cos(x2)+1.0+x1)))`\n",
    "     \n",
    "     `y2 = 1.1+sin(20*x1)`\n",
    "\n",
    "   Get the central value of y, and see if you can quickly differentiate this with\n",
    "   respect to `x1` and `x2`, and thus predict what uncertainty to expect for y using\n",
    "   the error propagation formula. It is (for once) OK to give up on the first expression :-)\n",
    "   Next, try to estimate the central value and uncertainty using random numbers\n",
    "   like above - do you trust this result more? And are the distributions Gaussian?\n",
    "\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "3. Try to generate `x1` and `x2` with e.g. a quadratic correlation, and see that despite\n",
    "   not having any linear correlation, the result on perimeter, area, and diagonal\n",
    "   length is still affected.\n",
    "\n",
    "---------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
